1.В IDE проблема с русской кодировкой, поэтому вывод в консоль и комментарии невозможно написать на русском
2. Вариант использования использования приложения на примере обучения Q-Learning агента:
-Акторы: Пользователь (разработчик / исследователь);
-Цель: научить QLearningAgent играть против детерминированного противника (RuleBasedAgent или LookaheadAgent);
-Предусловия:
1. Скрипт train_q.py доступен;
2. Установлены зависимости: библиотека numpy.
-Основной поток:
1. Пользователь запускает скрипт: python train_q.py;
2. Создаются два игрока:
2.1 QLearningAgent с параметрами epsilon=0.99, alpha=0.1, gamma=0.9;
2.2. Противник: например, RuleBasedAgent.
3. Инициализируется объект Game с этими игроками;
4. Начинается цикл обучения:
4.1. Агент делает ход;
4.2. Обновляется состояние доски;
4.3. Вычисляется награда за ход;
4.4. Происходит обновление Q-таблицы;
4.5. Каждые N шагов результаты логируются в CSV файл;
4.6. По окончании обучения сохраняется Q-таблица в папку checkpoints/.
-Альтернативный поток:
1. Пользователь может изменить количество эпизодов, параметры alpha, gamma, epsilon;
2. Пользователь может выбрать другого противника (например, RandomAgent).
-Постусловие:
1. Сохранена обученная Q-таблица;
2. Логи содержат данные о победах, ничьих, поражениях.
